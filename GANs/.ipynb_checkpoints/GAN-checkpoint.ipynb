{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d2538ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0002\n",
    "B1 = 0.5\n",
    "B2 = 0.999\n",
    "LATENT_DIM = 100\n",
    "IMG_SIZE = 28\n",
    "CHANNELS = 1\n",
    "SAMPLE_INTERVAL = 400\n",
    "\n",
    "SHUFFLE = True\n",
    "PIN_MEMORY = True\n",
    "\n",
    "img_shape = (CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:{}'.format(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2244728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% train data\n",
    "#transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "example_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True, num_workers=0,drop_last=True,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d449ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective: fake or no fake -> 1 output [0, 1]\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6363a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fake Data: output like real data [1, 28, 28] and values -1, 1\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(LATENT_DIM, 7*7*64)  # [n, 256, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass latent space input into linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)  #256\n",
    "        \n",
    "        # Upsample (transposed conv) 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Upsample to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Convolution to 28x28 (1 feature map)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a086ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    loss.cuda()\n",
    "    \n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR, betas=(B1 ,B2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR, betas=(B1, B2))\n",
    "   \n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9afbd75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 234/235] [D loss: 0.474425] [G loss: 1.770767]\n",
      "[Epoch 1/200] [Batch 234/235] [D loss: 0.353775] [G loss: 1.762827]\n",
      "[Epoch 2/200] [Batch 234/235] [D loss: 0.434579] [G loss: 1.766272]\n",
      "[Epoch 3/200] [Batch 234/235] [D loss: 0.469740] [G loss: 1.184781]\n",
      "[Epoch 4/200] [Batch 234/235] [D loss: 0.457011] [G loss: 1.196495]\n",
      "[Epoch 5/200] [Batch 234/235] [D loss: 0.530918] [G loss: 1.369695]\n",
      "[Epoch 6/200] [Batch 234/235] [D loss: 0.427755] [G loss: 1.498117]\n",
      "[Epoch 7/200] [Batch 234/235] [D loss: 0.480615] [G loss: 1.164920]\n",
      "[Epoch 8/200] [Batch 234/235] [D loss: 0.431550] [G loss: 1.260330]\n",
      "[Epoch 9/200] [Batch 234/235] [D loss: 0.525510] [G loss: 1.656740]\n",
      "[Epoch 10/200] [Batch 234/235] [D loss: 0.384358] [G loss: 1.196179]\n",
      "[Epoch 11/200] [Batch 234/235] [D loss: 0.458927] [G loss: 1.495539]\n",
      "[Epoch 12/200] [Batch 234/235] [D loss: 0.455194] [G loss: 1.295888]\n",
      "[Epoch 13/200] [Batch 234/235] [D loss: 0.597894] [G loss: 1.408056]\n",
      "[Epoch 14/200] [Batch 234/235] [D loss: 0.457016] [G loss: 1.095779]\n",
      "[Epoch 15/200] [Batch 234/235] [D loss: 0.533523] [G loss: 1.168321]\n",
      "[Epoch 16/200] [Batch 234/235] [D loss: 0.419131] [G loss: 1.216345]\n",
      "[Epoch 17/200] [Batch 234/235] [D loss: 0.505732] [G loss: 1.281965]\n",
      "[Epoch 18/200] [Batch 234/235] [D loss: 0.484478] [G loss: 1.242050]\n",
      "[Epoch 19/200] [Batch 234/235] [D loss: 0.476993] [G loss: 0.930540]\n",
      "[Epoch 20/200] [Batch 234/235] [D loss: 0.534509] [G loss: 1.349136]\n",
      "[Epoch 21/200] [Batch 234/235] [D loss: 0.515135] [G loss: 0.926375]\n",
      "[Epoch 22/200] [Batch 234/235] [D loss: 0.521062] [G loss: 1.249251]\n",
      "[Epoch 23/200] [Batch 234/235] [D loss: 0.451776] [G loss: 1.291901]\n",
      "[Epoch 24/200] [Batch 234/235] [D loss: 0.522938] [G loss: 1.083254]\n",
      "[Epoch 25/200] [Batch 234/235] [D loss: 0.539561] [G loss: 1.171901]\n",
      "[Epoch 26/200] [Batch 234/235] [D loss: 0.464884] [G loss: 1.073615]\n",
      "[Epoch 27/200] [Batch 234/235] [D loss: 0.485248] [G loss: 0.972994]\n",
      "[Epoch 28/200] [Batch 234/235] [D loss: 0.415666] [G loss: 1.154384]\n",
      "[Epoch 29/200] [Batch 234/235] [D loss: 0.510595] [G loss: 1.364593]\n",
      "[Epoch 30/200] [Batch 234/235] [D loss: 0.517820] [G loss: 1.099348]\n",
      "[Epoch 31/200] [Batch 234/235] [D loss: 0.421205] [G loss: 1.263673]\n",
      "[Epoch 32/200] [Batch 234/235] [D loss: 0.444082] [G loss: 1.222902]\n",
      "[Epoch 33/200] [Batch 234/235] [D loss: 0.483013] [G loss: 1.190792]\n",
      "[Epoch 34/200] [Batch 234/235] [D loss: 0.546536] [G loss: 1.317815]\n",
      "[Epoch 35/200] [Batch 234/235] [D loss: 0.480004] [G loss: 1.221580]\n",
      "[Epoch 36/200] [Batch 234/235] [D loss: 0.554822] [G loss: 1.084558]\n",
      "[Epoch 37/200] [Batch 234/235] [D loss: 0.547355] [G loss: 1.227198]\n",
      "[Epoch 38/200] [Batch 234/235] [D loss: 0.579512] [G loss: 1.155489]\n",
      "[Epoch 39/200] [Batch 234/235] [D loss: 0.498880] [G loss: 1.227793]\n",
      "[Epoch 40/200] [Batch 234/235] [D loss: 0.529625] [G loss: 1.053149]\n",
      "[Epoch 41/200] [Batch 234/235] [D loss: 0.463276] [G loss: 1.290810]\n",
      "[Epoch 42/200] [Batch 234/235] [D loss: 0.566634] [G loss: 1.071138]\n",
      "[Epoch 43/200] [Batch 234/235] [D loss: 0.609124] [G loss: 1.588595]\n",
      "[Epoch 44/200] [Batch 234/235] [D loss: 0.550798] [G loss: 1.058209]\n",
      "[Epoch 45/200] [Batch 234/235] [D loss: 0.517699] [G loss: 1.277107]\n",
      "[Epoch 46/200] [Batch 234/235] [D loss: 0.510031] [G loss: 1.111805]\n",
      "[Epoch 47/200] [Batch 234/235] [D loss: 0.534497] [G loss: 1.015486]\n",
      "[Epoch 48/200] [Batch 234/235] [D loss: 0.499958] [G loss: 1.327356]\n",
      "[Epoch 49/200] [Batch 234/235] [D loss: 0.483431] [G loss: 1.161975]\n",
      "[Epoch 50/200] [Batch 234/235] [D loss: 0.524093] [G loss: 1.011959]\n",
      "[Epoch 51/200] [Batch 234/235] [D loss: 0.588439] [G loss: 0.832473]\n",
      "[Epoch 52/200] [Batch 234/235] [D loss: 0.455443] [G loss: 1.141725]\n",
      "[Epoch 53/200] [Batch 234/235] [D loss: 0.537675] [G loss: 1.161635]\n",
      "[Epoch 54/200] [Batch 234/235] [D loss: 0.476736] [G loss: 1.055802]\n",
      "[Epoch 55/200] [Batch 234/235] [D loss: 0.551613] [G loss: 1.071705]\n",
      "[Epoch 56/200] [Batch 234/235] [D loss: 0.472985] [G loss: 1.076677]\n",
      "[Epoch 57/200] [Batch 234/235] [D loss: 0.486302] [G loss: 1.112075]\n",
      "[Epoch 58/200] [Batch 234/235] [D loss: 0.560863] [G loss: 1.109138]\n",
      "[Epoch 59/200] [Batch 234/235] [D loss: 0.516685] [G loss: 1.052298]\n",
      "[Epoch 60/200] [Batch 234/235] [D loss: 0.612126] [G loss: 1.495158]\n",
      "[Epoch 61/200] [Batch 234/235] [D loss: 0.508019] [G loss: 1.285225]\n",
      "[Epoch 62/200] [Batch 234/235] [D loss: 0.513425] [G loss: 1.163418]\n",
      "[Epoch 63/200] [Batch 234/235] [D loss: 0.527385] [G loss: 0.911978]\n",
      "[Epoch 64/200] [Batch 234/235] [D loss: 0.554878] [G loss: 0.993588]\n",
      "[Epoch 65/200] [Batch 234/235] [D loss: 0.566631] [G loss: 1.064505]\n",
      "[Epoch 66/200] [Batch 234/235] [D loss: 0.508622] [G loss: 1.108102]\n",
      "[Epoch 67/200] [Batch 234/235] [D loss: 0.609878] [G loss: 1.008273]\n",
      "[Epoch 68/200] [Batch 234/235] [D loss: 0.532010] [G loss: 1.230089]\n",
      "[Epoch 69/200] [Batch 234/235] [D loss: 0.523194] [G loss: 1.191972]\n",
      "[Epoch 70/200] [Batch 234/235] [D loss: 0.523188] [G loss: 1.106705]\n",
      "[Epoch 71/200] [Batch 234/235] [D loss: 0.485287] [G loss: 1.001845]\n",
      "[Epoch 72/200] [Batch 234/235] [D loss: 0.540504] [G loss: 1.103520]\n",
      "[Epoch 73/200] [Batch 234/235] [D loss: 0.527396] [G loss: 1.560271]\n",
      "[Epoch 74/200] [Batch 234/235] [D loss: 0.517348] [G loss: 1.162448]\n",
      "[Epoch 75/200] [Batch 234/235] [D loss: 0.504797] [G loss: 1.072621]\n",
      "[Epoch 76/200] [Batch 234/235] [D loss: 0.541901] [G loss: 1.146198]\n",
      "[Epoch 77/200] [Batch 234/235] [D loss: 0.505384] [G loss: 0.955880]\n",
      "[Epoch 78/200] [Batch 234/235] [D loss: 0.469542] [G loss: 1.171544]\n",
      "[Epoch 79/200] [Batch 234/235] [D loss: 0.515703] [G loss: 0.941056]\n",
      "[Epoch 80/200] [Batch 234/235] [D loss: 0.574449] [G loss: 1.058489]\n",
      "[Epoch 81/200] [Batch 234/235] [D loss: 0.580124] [G loss: 1.047672]\n",
      "[Epoch 82/200] [Batch 234/235] [D loss: 0.573971] [G loss: 1.066385]\n",
      "[Epoch 83/200] [Batch 234/235] [D loss: 0.515151] [G loss: 1.195745]\n",
      "[Epoch 84/200] [Batch 234/235] [D loss: 0.532646] [G loss: 1.074293]\n",
      "[Epoch 85/200] [Batch 234/235] [D loss: 0.541309] [G loss: 1.051708]\n",
      "[Epoch 86/200] [Batch 234/235] [D loss: 0.559927] [G loss: 1.123864]\n",
      "[Epoch 87/200] [Batch 234/235] [D loss: 0.500837] [G loss: 1.237491]\n",
      "[Epoch 88/200] [Batch 234/235] [D loss: 0.486218] [G loss: 1.154001]\n",
      "[Epoch 89/200] [Batch 234/235] [D loss: 0.515825] [G loss: 1.165057]\n",
      "[Epoch 90/200] [Batch 234/235] [D loss: 0.610176] [G loss: 1.122091]\n",
      "[Epoch 91/200] [Batch 234/235] [D loss: 0.544813] [G loss: 1.088383]\n",
      "[Epoch 92/200] [Batch 234/235] [D loss: 0.605170] [G loss: 0.960332]\n",
      "[Epoch 93/200] [Batch 234/235] [D loss: 0.554136] [G loss: 1.089041]\n",
      "[Epoch 94/200] [Batch 234/235] [D loss: 0.475620] [G loss: 1.080949]\n",
      "[Epoch 95/200] [Batch 234/235] [D loss: 0.535638] [G loss: 1.005381]\n",
      "[Epoch 96/200] [Batch 234/235] [D loss: 0.552225] [G loss: 1.189845]\n",
      "[Epoch 97/200] [Batch 234/235] [D loss: 0.519706] [G loss: 1.062229]\n",
      "[Epoch 98/200] [Batch 234/235] [D loss: 0.611102] [G loss: 1.166476]\n",
      "[Epoch 99/200] [Batch 234/235] [D loss: 0.484981] [G loss: 1.210781]\n",
      "[Epoch 100/200] [Batch 234/235] [D loss: 0.621933] [G loss: 1.045095]\n",
      "[Epoch 101/200] [Batch 234/235] [D loss: 0.577618] [G loss: 0.984421]\n",
      "[Epoch 102/200] [Batch 234/235] [D loss: 0.518979] [G loss: 1.048343]\n",
      "[Epoch 103/200] [Batch 234/235] [D loss: 0.608259] [G loss: 0.980334]\n",
      "[Epoch 104/200] [Batch 234/235] [D loss: 0.608701] [G loss: 1.103274]\n",
      "[Epoch 105/200] [Batch 234/235] [D loss: 0.518722] [G loss: 0.979761]\n",
      "[Epoch 106/200] [Batch 234/235] [D loss: 0.571257] [G loss: 1.146328]\n",
      "[Epoch 107/200] [Batch 234/235] [D loss: 0.597035] [G loss: 0.999114]\n",
      "[Epoch 108/200] [Batch 234/235] [D loss: 0.580228] [G loss: 1.192427]\n",
      "[Epoch 109/200] [Batch 234/235] [D loss: 0.550239] [G loss: 1.152698]\n",
      "[Epoch 110/200] [Batch 234/235] [D loss: 0.589862] [G loss: 1.078168]\n",
      "[Epoch 111/200] [Batch 234/235] [D loss: 0.473484] [G loss: 1.137968]\n",
      "[Epoch 112/200] [Batch 234/235] [D loss: 0.533732] [G loss: 1.118944]\n",
      "[Epoch 113/200] [Batch 234/235] [D loss: 0.579062] [G loss: 1.289882]\n",
      "[Epoch 114/200] [Batch 234/235] [D loss: 0.519368] [G loss: 1.117280]\n",
      "[Epoch 115/200] [Batch 234/235] [D loss: 0.518714] [G loss: 0.950665]\n",
      "[Epoch 116/200] [Batch 234/235] [D loss: 0.550142] [G loss: 1.095259]\n",
      "[Epoch 117/200] [Batch 234/235] [D loss: 0.543115] [G loss: 1.214141]\n",
      "[Epoch 118/200] [Batch 234/235] [D loss: 0.555860] [G loss: 1.028495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 119/200] [Batch 234/235] [D loss: 0.553420] [G loss: 0.981236]\n",
      "[Epoch 120/200] [Batch 234/235] [D loss: 0.547523] [G loss: 1.097099]\n",
      "[Epoch 121/200] [Batch 234/235] [D loss: 0.589675] [G loss: 1.083961]\n",
      "[Epoch 122/200] [Batch 234/235] [D loss: 0.608742] [G loss: 1.377674]\n",
      "[Epoch 123/200] [Batch 234/235] [D loss: 0.522362] [G loss: 1.118392]\n",
      "[Epoch 124/200] [Batch 234/235] [D loss: 0.574621] [G loss: 1.160586]\n",
      "[Epoch 125/200] [Batch 234/235] [D loss: 0.516716] [G loss: 1.099505]\n",
      "[Epoch 126/200] [Batch 234/235] [D loss: 0.526034] [G loss: 1.322436]\n",
      "[Epoch 127/200] [Batch 234/235] [D loss: 0.563060] [G loss: 1.191782]\n",
      "[Epoch 128/200] [Batch 234/235] [D loss: 0.543718] [G loss: 1.065201]\n",
      "[Epoch 129/200] [Batch 234/235] [D loss: 0.543605] [G loss: 1.077541]\n",
      "[Epoch 130/200] [Batch 234/235] [D loss: 0.502782] [G loss: 1.188938]\n",
      "[Epoch 131/200] [Batch 234/235] [D loss: 0.459032] [G loss: 1.365377]\n",
      "[Epoch 132/200] [Batch 234/235] [D loss: 0.565160] [G loss: 1.189837]\n",
      "[Epoch 133/200] [Batch 234/235] [D loss: 0.560797] [G loss: 1.343732]\n",
      "[Epoch 134/200] [Batch 234/235] [D loss: 0.524007] [G loss: 1.342489]\n",
      "[Epoch 135/200] [Batch 234/235] [D loss: 0.547705] [G loss: 1.273459]\n",
      "[Epoch 136/200] [Batch 234/235] [D loss: 0.512501] [G loss: 1.298234]\n",
      "[Epoch 137/200] [Batch 234/235] [D loss: 0.553634] [G loss: 1.087367]\n",
      "[Epoch 138/200] [Batch 234/235] [D loss: 0.567587] [G loss: 1.328876]\n",
      "[Epoch 139/200] [Batch 234/235] [D loss: 0.566019] [G loss: 1.251433]\n",
      "[Epoch 140/200] [Batch 234/235] [D loss: 0.482963] [G loss: 1.007284]\n",
      "[Epoch 141/200] [Batch 234/235] [D loss: 0.496536] [G loss: 1.411237]\n",
      "[Epoch 142/200] [Batch 234/235] [D loss: 0.545680] [G loss: 1.055634]\n",
      "[Epoch 143/200] [Batch 234/235] [D loss: 0.521544] [G loss: 1.053064]\n",
      "[Epoch 144/200] [Batch 234/235] [D loss: 0.527245] [G loss: 1.067581]\n",
      "[Epoch 145/200] [Batch 234/235] [D loss: 0.461718] [G loss: 1.033876]\n",
      "[Epoch 146/200] [Batch 234/235] [D loss: 0.510264] [G loss: 1.090804]\n",
      "[Epoch 147/200] [Batch 234/235] [D loss: 0.540060] [G loss: 1.174265]\n",
      "[Epoch 148/200] [Batch 234/235] [D loss: 0.541788] [G loss: 1.100634]\n",
      "[Epoch 149/200] [Batch 234/235] [D loss: 0.468127] [G loss: 1.165986]\n",
      "[Epoch 150/200] [Batch 234/235] [D loss: 0.575054] [G loss: 1.200258]\n",
      "[Epoch 151/200] [Batch 234/235] [D loss: 0.518774] [G loss: 1.122163]\n",
      "[Epoch 152/200] [Batch 234/235] [D loss: 0.510917] [G loss: 1.172052]\n",
      "[Epoch 153/200] [Batch 234/235] [D loss: 0.512704] [G loss: 1.238248]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15724\\252989466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# Adversarial ground truths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \"\"\"\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],LATENT_DIM))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        batches_done = epoch * len(train_loader) + i\n",
    "       \n",
    "    \n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "        % (epoch,NUM_EPOCHS, i, len(train_loader), d_loss.item(), g_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "856c58d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input image \n",
    "z = Variable(Tensor(np.random.normal(0, 1, (256,100)))).cpu()\n",
    "f, axarr = plt.subplots(1)\n",
    "axarr.imshow(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "83b508e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],LATENT_DIM)))).cpu()\n",
    "rand_latent = torch.rand(imgs.shape[0],LATENT_DIM).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3c6b79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator.to('cpu')\n",
    "discriminator.to('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    f, axarr = plt.subplots(1)\n",
    "    \n",
    "    rand_latent = torch.rand(imgs.shape[0],LATENT_DIM).cpu()\n",
    "    print(rand_latent.shape)\n",
    "    \n",
    "    fake_image = generator(rand_latent)\n",
    "    \n",
    "    #axarr[1].imshow(z[0].cpu())\n",
    "   \n",
    "    fake_image = fake_image[0].reshape(-1, 28, 28)\n",
    "    axarr.imshow(fake_image[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cc8e2103",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "Discriminator Prediction: tensor([[0.7654]]),Should be: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator.to('cpu')\n",
    "discriminator.to('cpu')\n",
    "with torch.no_grad():\n",
    "    for image, _ in example_loader:\n",
    "        int = 0#random.randint(0, 1)\n",
    "        f, axarr = plt.subplots(1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        #z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],LATENT_DIM)))).cpu()\n",
    "        #fake_image = generator(z)[0]#.detach().numpy()\n",
    "        \n",
    "        \n",
    "        image = image.reshape(-1, 28, 28)\n",
    "        print(fake_image.shape)\n",
    "        \n",
    "        #feed discriminator fake image, expect \"0\" output\n",
    "        if int == 0:\n",
    "            axarr.imshow(fake_image[0])\n",
    "            pred = discriminator(fake_image)\n",
    "            print(\"Discriminator Prediction: {},Should be: {}\".format(pred,\"0\"))\n",
    "        #feed discriminator real image, expect \"1\" output\n",
    "        else:\n",
    "            axarr.imshow(image[0])\n",
    "            pred = discriminator(image)\n",
    "            print(\"Discriminator Prediction: {},Should be: {}\".format(pred,\"1\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "62d0c5cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15724\\1517050423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfake_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15724\\2977459275.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Pass latent space input into linear layer and reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cdab58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(fake_image.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26095fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
