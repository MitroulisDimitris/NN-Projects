{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d592cb",
   "metadata": {},
   "source": [
    "## TF-IDF \n",
    "- Is a more sohisticated count Vectorizer\n",
    "\n",
    "#### What's the need?\n",
    "\n",
    "1. Stopwords list are not usefull\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "Dynamic lists of stopwords based on frequency of use\n",
    "\n",
    "**T**erm **F**requency - **I**nverse **D**ocument **F**requency\n",
    "\n",
    "\n",
    "$$\n",
    "\\ TF-IDF = \\frac{Term Frequency}{Document Frequency}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ tfidf(t,d) = tf(t,d) * idf(t)\n",
    "$$\n",
    "<div style=\"text-align: left;\">\n",
    "\n",
    "Where:\n",
    "\n",
    "t: term\\\n",
    "d: document\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234b3a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Dimitris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc8e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams\\n\\nBT is intr...      tech\n",
       "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech\n",
       "2222  Be careful how you code\\n\\nA new European dire...      tech\n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...      tech\n",
       "2224  Losing yourself in online gaming\\n\\nOnline rol...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file using pandas\n",
    "df = pd.read_csv('datasets/bbc_text_cls.csv')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36af847",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['text']\n",
    "labels = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, inputs_test, Ytrain, Ytest = train_test_split(\n",
    "    inputs,labels,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a315d888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "for doc in df['text']:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "            \n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a205b147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34762"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bba8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2words = []\n",
    "for word in word2idx.keys():\n",
    "    idx2words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd30296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of rows\n",
    "N = len(df['text'])\n",
    "# num of words\n",
    "V = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc344f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# term-requency matrix\n",
    "# same dim as count vectorizer\n",
    "tf = np.zeros((N,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a056aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate matrix\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i, j] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646712f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute IDF\n",
    "document_freq = np.sum(tf>0, axis=0)\n",
    "idf = np.log(N / document_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80486125",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "822774af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346\n",
      "Label: sport\n",
      "Text: Athens memories soar above lows\n",
      "Top 5 terms:\n",
      "paula\n",
      "athens\n",
      "1500m\n",
      "her\n",
      "kelly\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "# pick a random document, show top 5 terms\n",
    "i = np.random.choice(N)\n",
    "print(i)\n",
    "row = df.iloc[i]\n",
    "print('Label:', row['labels'])\n",
    "print('Text:', row['text'].split('\\n',1)[0])\n",
    "print('Top 5 terms:')\n",
    "\n",
    "scores = tf_idf[i]\n",
    "indices = (-scores).argsort()\n",
    "\n",
    "for j in indices[:5]:\n",
    "    print(idx2words[j])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
