{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder Consists of:  \n",
    "\n",
    "    1. Encoder\n",
    "    2. Decoder\n",
    "    \n",
    "Encoder/Decoder are fully connected feed foward neural networks\n",
    "and the bottleneck is \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import torchvision.utils as vutils\n",
    "from  torch.utils import data\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 150\n",
    "LR = 1e-3\n",
    "LATENT_DIM = 100\n",
    "IMG_SIZE = 28\n",
    "CHANNELS = 1\n",
    "B1 = 0.5\n",
    "B2 = 0.999\n",
    "\n",
    "\n",
    "GEN_STATE_DICT = \"gen_state_dict\"\n",
    "DISC_STATE_DICT = \"disc_state_dict\"\n",
    "GEN_OPTIMIZER = \"gen_optimizer\"\n",
    "DISC_OPTIMIZER = \"disc_optimizer\"\n",
    "G_LOSSES = \"g_losses\"\n",
    "D_LOSSES = \"d_losses\"\n",
    "\n",
    "\n",
    "\n",
    "SHUFFLE = True\n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 750\n",
    "\n",
    "specific_latent = torch.tensor([[0.7628, 0.1779, 0.3978, 0.3606, 0.6387,\n",
    "         0.3044, 0.8340, 0.3884, 0.9313, 0.5635, 0.1994, 0.6934, 0.5326,\n",
    "         0.3676, 0.5342, 0.9480, 0.4120, 0.5845, 0.4035, 0.5298, 0.0177,\n",
    "         0.5605, 0.6453, 0.9576, 0.7153, 0.1923, 0.8122, 0.0937, 0.5744,\n",
    "         0.5951, 0.8890, 0.4838, 0.5707, 0.6760, 0.3738, 0.2796, 0.1549,\n",
    "         0.8220, 0.2800, 0.4051, 0.2553, 0.1831, 0.0046, 0.9021, 0.0264,\n",
    "         0.2327, 0.8261, 0.0534, 0.1582, 0.4087, 0.9047, 0.1409, 0.6864,\n",
    "         0.1439, 0.3432, 0.1072, 0.5907, 0.6756, 0.6942, 0.6814, 0.3368,\n",
    "         0.4138, 0.8030, 0.7024, 0.3309, 0.7288, 0.2193, 0.1954, 0.9948,\n",
    "         0.1201, 0.9483, 0.7407, 0.4849, 0.6500, 0.8649, 0.7405, 0.4725,\n",
    "         0.5373, 0.6541, 0.5444, 0.7425, 0.8940, 0.3580, 0.3905, 0.8924,\n",
    "         0.2995, 0.3726, 0.5399, 0.3057, 0.3380, 0.8313, 0.1137, 0.0120,\n",
    "         0.7714, 0.2561, 0.2569, 0.2994, 0.7648, 0.2413, 0.6101\n",
    "        ]])\n",
    "\n",
    "\n",
    "img_shape = (CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:{}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "                                train_dataset,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=SHUFFLE,\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                pin_memory=PIN_MEMORY\n",
    "                                )\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "                                test_dataset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0\n",
    "                                )\n",
    "\n",
    "example_loader = data.DataLoader(\n",
    "                                train_dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0,\n",
    "                                drop_last=True,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def plot():\n",
    "    f, axarr = plt.subplots(2)\n",
    "\n",
    "    for i, item in enumerate(image):\n",
    "    # Reshape the array for plotting\n",
    "        item = item.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(item[0].cpu())\n",
    "\n",
    "    for i, item in enumerate(reconstructed):\n",
    "        item = item.reshape(-1, 28, 28).cpu()\n",
    "        item = item.detach().numpy()\n",
    "        axarr[1].imshow(item[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "def showExample():\n",
    "    for image, _ in example_loader:\n",
    "        f, axarr = plt.subplots(2)\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "\n",
    "        model.to(device)\n",
    "        recon = model(image)\n",
    "\n",
    "        image = image.reshape(-1, 28, 28)\n",
    "        axarr[0].imshow(image[0].cpu())\n",
    "\n",
    "\n",
    "        recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "        axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "        break\n",
    "\n",
    "def add_noise(inputs,variance):\n",
    "    noise = torch.randn_like(inputs)\n",
    "    return inputs + variance*noise\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    print(\"=> Saving chekpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    generator.load_state_dict(checkpoint[GEN_STATE_DICT])\n",
    "    optimizer_G.load_state_dict(checkpoint[GEN_OPTIMIZER])\n",
    "    discriminator.load_state_dict(checkpoint[DISC_STATE_DICT])\n",
    "    optimizer_D.load_state_dict(checkpoint[DISC_OPTIMIZER])\n",
    "    if 'G_losses' in locals() and 'D_losses' in locals():\n",
    "        G_losses.load_state_dict(checkpoint[G_LOSSES])\n",
    "        D_losses.load_state_dict(checkpoint[D_LOSSES])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will be constructing the encoder and decoder, 2 fully connected, feed forward Neural networks  \n",
    "\n",
    "Encoder will gradually reduce dimentionality  \n",
    "28*28=784 -> 128 -> 64 -> 36 -> 18 -> 9\n",
    "  \n",
    "Decoder will do the opposite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28  #784\n",
    "hidden_size = 128\n",
    "code_size = 32\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Encoder \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,code_size)\n",
    "        )\n",
    "        \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(code_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.model = nn.Sequential(\n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Initialization\n",
    "model = autoencoder()\n",
    "\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(B1 ,B2))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    loss_function.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model for 20 epoch:\n",
    "Things to notice:\n",
    "- Firstly we are setting to zero gradient before each backpropagation\n",
    "    because pytorch accumulates the gradients on subsequent backward losses\n",
    "    (this may be usefull when training RNNs)\n",
    "- then we are passing the image through the model and calculate loss with a simple MSE Loss$$ (x - g(f(x)))^{2} $$\n",
    "\n",
    "- loss.backward() computes loss and we are preforming backpropagation with optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "losses = []\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for image, _ in train_loader:\n",
    "        image = image.reshape(-1,28*28).to(device)\n",
    "        noised_image = add_noise(image,0.2)\n",
    "        #set gradients to zero\n",
    "        \n",
    "        reconstructed = model(noised_image)\n",
    "        loss = loss_function(reconstructed , noised_image)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Preforms Backpropagation and calculates  gradients \n",
    "        optimizer.step() # Updates Weights based on the gradients computed above\n",
    "        losses.append(loss.item())\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss.item()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for image, _ in train_loader:\n",
    "    #example = torch.movedim(image[0],(1,2),(0,1))\n",
    "   \n",
    "    f, axarr = plt.subplots(2)\n",
    "    image = image.reshape(-1,28*28).to(device)\n",
    "    \n",
    "    image = add_noise(image,0.0)\n",
    "    model.to(device)\n",
    "    recon = model(image)\n",
    "    image = image.reshape(-1, 28, 28)\n",
    "   \n",
    "    axarr[0].imshow(image[0].cpu())\n",
    "    \n",
    "\n",
    "    \n",
    "    recon = recon.reshape(-1, 28, 28).to('cpu')\n",
    "    #example = torch.movedim(example,(0,1,2),(-1,-2,-3))\n",
    "    axarr[1].imshow(recon[0].detach().numpy())\n",
    "\n",
    "    break    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
